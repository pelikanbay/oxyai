# Model Selection - RecyeAI

## Descriere
Model Selection permite utilizatorilor sÄƒ aleagÄƒ modelul AI È™i sÄƒ ajusteze parametrii pentru a controla comportamentul rÄƒspunsurilor. Toate modelele disponibile sunt **100% gratuite** prin OpenRouter.

## Modele Disponibile (FREE)

### 1. DeepSeek R1 Qwen3 8B âš¡ (DEFAULT)
- **Provider**: DeepSeek
- **Context**: 8K tokens
- **Speed**: Fast
- **Capabilities**: Coding, Analysis, Reasoning, Pentesting
- **Best For**: Analytical tasks, coding, penetration testing
- **Recomandat pentru**: Red teaming, vulnerability analysis

### 2. Qwen 2.5 7B Instruct âš¡
- **Provider**: Alibaba
- **Context**: 32K tokens
- **Speed**: Fast
- **Capabilities**: General, Coding, Multilingual
- **Best For**: General purpose tasks cu context mare
- **Recomandat pentru**: Documentation, long conversations

### 3. Llama 3.2 3B Instruct âš¡
- **Provider**: Meta
- **Context**: 128K tokens (!!)
- **Speed**: Fast
- **Capabilities**: Conversation, General, Fast
- **Best For**: Simple tasks cu context foarte mare
- **Recomandat pentru**: Long document analysis

### 4. Phi-3 Mini 128K âš¡
- **Provider**: Microsoft
- **Context**: 128K tokens
- **Speed**: Fast
- **Capabilities**: Coding, Math, Reasoning
- **Best For**: Technical problems, mathematics
- **Recomandat pentru**: Complex calculations, code review

### 5. Mistral 7B Instruct ğŸ•
- **Provider**: Mistral AI
- **Context**: 32K tokens
- **Speed**: Medium
- **Capabilities**: General, Conversation, Coding
- **Best For**: Balanced performance
- **Recomandat pentru**: General pentesting queries

### 6. Gemma 2 9B IT ğŸ•
- **Provider**: Google
- **Context**: 8K tokens
- **Speed**: Medium
- **Capabilities**: General, Safety, Reasoning
- **Best For**: Safety-focused tasks
- **Recomandat pentru**: Compliance questions, safe coding

## Parametri AI

### TemperaturÄƒ (Temperature)
Control asupra creativitÄƒÈ›ii È™i randomness-ului rÄƒspunsurilor.

**Range**: 0.0 - 1.5

**Valori Recomandate:**
- **0.0 - 0.3**: Precis
  - RÄƒspunsuri deterministice
  - AceeaÈ™i Ã®ntrebare = acelaÈ™i rÄƒspuns
  - Perfect pentru: code generation, exact answers
  
- **0.4 - 0.7**: Balansat (DEFAULT: 0.7)
  - Mix Ã®ntre precizie È™i creativitate
  - VariaÈ›ie moderatÄƒ
  - Perfect pentru: conversaÈ›ii generale, explanations
  
- **0.8 - 1.0**: Creativ
  - RÄƒspunsuri mai diverse
  - Mai mult "out of the box thinking"
  - Perfect pentru: brainstorming, ideation
  
- **1.1 - 1.5**: Foarte Creativ
  - Maximum randomness
  - Poate produce rÄƒspunsuri neaÈ™teptate
  - Perfect pentru: creative writing, unusual approaches

### Impact Ã®n Cybersecurity Context:

**Low Temperature (0.0-0.3)**: Pentesting Scripts
```
User: "Write a Nmap scan command for port scanning"
Response (temp=0.2): nmap -sS -p- -T4 192.168.1.1
(Mereu acelaÈ™i rÄƒspuns, corect È™i precis)
```

**Medium Temperature (0.4-0.7)**: Explanations
```
User: "Explain SQL injection"
Response (temp=0.7): Varies slightly, includes different examples
(Diverse explicaÈ›ii, toate corecte)
```

**High Temperature (0.8-1.5)**: Attack Scenarios
```
User: "Suggest creative attack vectors"
Response (temp=1.2): Unusual, creative approaches
(Idei neconvenÈ›ionale, poate miss some classics)
```

## Cum SÄƒ Alegi Modelul

### Pentru Pentesting & Red Teaming:
**DeepSeek R1 Qwen3 8B** (default) - Best all-rounder
- Rapid, bun la reasoning
- Perfect pentru analytical tasks

### Pentru Long Documents:
**Llama 3.2 3B** sau **Phi-3 Mini**
- 128K tokens context
- AnalizeazÄƒ rapoarte mari de vulnerabilitÄƒÈ›i

### Pentru ConversaÈ›ii Generale:
**Mistral 7B** sau **Qwen 2.5**
- Balanced performance
- Good pentru mixed tasks

### Pentru Compliance & Safety:
**Gemma 2 9B**
- Safety-focused
- Good pentru legal/compliance questions

## UI/UX

### LocaÈ›ie
- **Desktop**: Top bar Ã®n chat, sub header
- **Mobile**: AcelaÈ™i, dar condensat

### Componente Vizuale

**Model Selector Button:**
- IconiÈ›Äƒ Brain (ğŸ§ )
- Numele modelului curent (trunked pe mobile)
- Chevron down pentru dropdown

**Dropdown Menu:**
- Lista tuturor modelelor gratuite
- Pentru fiecare model:
  - Nume + Check mark (dacÄƒ selectat)
  - Speed icon (âš¡ fast, ğŸ• medium)
  - Description (1-2 lines)
  - Capability badges (max 3)
  - Context window badge
- Footer cu info despre rate limits

**Settings Button:**
- IconiÈ›Äƒ Info (â„¹ï¸)
- Toggle pentru a arÄƒta/ascunde temperature slider

**Temperature Slider:**
- Range: 0.0 - 1.5
- Step: 0.1
- Label: "Creativitate"
- Badge cu nivel: Precis/Balansat/Creativ/Foarte Creativ
- Display numeric: 0.7

### State Management

**localStorage Keys:**
```typescript
{
  "recyeai_model_settings": {
    "selectedModel": "deepseek/deepseek-r1-0528-qwen3-8b:free",
    "temperature": 0.7
  }
}
```

**Persist:**
- Model selection persistÄƒ Ã®ntre sesiuni
- Temperature persistÄƒ Ã®ntre sesiuni
- Se aplicÄƒ tuturor conversaÈ›iilor noi

**Per-conversation:**
- Settings sunt globale, nu per-conversaÈ›ie
- DacÄƒ vrei behavior diferit, schimbÄƒ Ã®nainte de a trimite

## Rate Limits (FREE Models)

### OpenRouter Free Tier:
- **Requests Per Minute (RPM)**: ~20-60 (varies per model)
- **Tokens Per Day**: Limited but generous
- **No Cost**: 100% free

### Handling Rate Limits:

**429 Error (Rate Limited):**
```
Error: "Rate limit depÄƒÈ™it. Te rog Ã®ncearcÄƒ din nou Ã®n cÃ¢teva momente."
```

**Solution:**
1. AÈ™teaptÄƒ 60 secunde
2. Retry request
3. Consider spacing out requests

**Best Practices:**
- Nu trimite rapid multiple requests
- FoloseÈ™te Ghost Mode pentru teste intensive
- Space out requests cu ~2-3 secunde Ã®ntre ele

## CombinaÈ›ii Recomandate

### Maximum Privacy + Performance:
- **Model**: DeepSeek R1 (fast)
- **Temperature**: 0.7 (balanced)
- **Ghost Mode**: ON
- **Voice Mode**: OFF

### Interactive Pentesting Session:
- **Model**: DeepSeek R1
- **Temperature**: 0.5 (precise)
- **Ghost Mode**: ON
- **Voice Mode**: ON

### Creative Attack Planning:
- **Model**: Mistral 7B
- **Temperature**: 1.0 (creative)
- **Ghost Mode**: ON
- **Voice Mode**: OFF

### Documentation Analysis:
- **Model**: Llama 3.2 3B (128K context)
- **Temperature**: 0.3 (precise)
- **Ghost Mode**: OFF (save for reference)
- **Voice Mode**: OFF

## Troubleshooting

### "Model nu rÄƒspunde / Timeout"
- Check OpenRouter status
- Try alt model din listÄƒ
- Check rate limits (429 error)

### "RÄƒspunsuri inconsistente"
- Lower temperature pentru consistency
- DeepSeek R1 e cel mai consistent la temp<0.5

### "Context prea mic / Truncated responses"
- Switch to Llama 3.2 (128K) sau Phi-3 (128K)
- Break down Ã®ntrebarea Ã®n pÄƒrÈ›i mai mici

### "Model nu Ã®nÈ›elege romÃ¢nÄƒ"
- Toate modelele suportÄƒ romÃ¢nÄƒ
- DeepSeek R1 È™i Qwen 2.5 sunt best la multilingual

## ComparaÈ›ie Modele

| Model | Speed | Context | Best For | Multilingual |
|-------|-------|---------|----------|--------------|
| DeepSeek R1 | âš¡âš¡âš¡ | 8K | Coding, Analysis | âœ… |
| Qwen 2.5 | âš¡âš¡âš¡ | 32K | General, Code | âœ…âœ… |
| Llama 3.2 | âš¡âš¡âš¡ | 128K | Long docs | âœ… |
| Phi-3 Mini | âš¡âš¡âš¡ | 128K | Math, Code | âœ… |
| Mistral 7B | âš¡âš¡ | 32K | Balanced | âœ… |
| Gemma 2 | âš¡âš¡ | 8K | Safety | âœ… |

**Legend:**
- âš¡âš¡âš¡ = Very Fast (<2s)
- âš¡âš¡ = Fast (2-4s)
- âš¡ = Medium (4-6s)

## API Integration

### Edge Function (`chat/index.ts`):
```typescript
const { message, files, model, temperature } = await req.json();

const selectedModel = model || "deepseek/deepseek-r1-0528-qwen3-8b:free";
const selectedTemperature = temperature ?? 0.7;

const response = await fetch("https://openrouter.ai/api/v1/chat/completions", {
  method: "POST",
  headers: {
    Authorization: `Bearer ${OPENROUTER_API_KEY}`,
    "Content-Type": "application/json",
  },
  body: JSON.stringify({
    model: selectedModel,
    temperature: selectedTemperature,
    messages: [...],
    stream: true,
  }),
});
```

### Frontend (`Hero.tsx`):
```typescript
const { selectedModel, temperature } = useModelSettings();

const resp = await fetch(CHAT_URL, {
  body: JSON.stringify({ 
    message: input,
    files: filesData,
    model: selectedModel,
    temperature: temperature
  }),
});
```

## Planuri Viitoare

- [ ] Per-conversation model selection
- [ ] Model comparison mode (2 models side-by-side)
- [ ] Custom system prompts per model
- [ ] Token usage tracking È™i visualization
- [ ] Model performance benchmarks
- [ ] Auto-select best model based on query type
- [ ] Paid models support (GPT-5, Claude)
- [ ] Fine-tuned RecyeAI model (specialized)

## Cod SursÄƒ

### Hook
- `src/hooks/useModelSettings.tsx` - State management + model definitions

### Componente
- `src/components/ModelSelector.tsx` - UI pentru selection + settings

### Edge Function
- `supabase/functions/chat/index.ts` - API integration

### Integrare
- `src/components/Hero.tsx` - Usage in chat
